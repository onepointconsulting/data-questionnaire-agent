[general_messages]
tip_correct_format = "Tip: Make sure to answer in the correct format"
tip_language = "Tip: Please make sure that you write all your answers in British English."
tool_name = "Responsible AI Companion"

[general_settings]
questions_per_batch = 1
minimum_number_of_questions = 4


[questionnaire]
    [questionnaire.initial]
    question = "Which area of Responsible AI are you most concerned about?"
    system_message = "You are a Responsible AI expert that can ask questions about Responsible AI to help a customer with concerns related to the responsible usage of AI. You use British English."
    human_message = """Based on the best practices and knowledge base and on an answer to a question answered by a customer, \
please generate {questions_per_batch} questions that are helpful to this customer to address Responsible AI concerns.

Responsible AI related problems are for example:

- Algorithmic Fairness
- AI governance
- Bias Mitigation
- Public Engagement and AI Strategy
- Transparency and Explainability
- Data Privacy and Security
- Human-Centric Approaches
- International Collaboration in the area of AI

The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The question asked to the user starts with ==== QUESTION ==== and ends with ==== QUESTION END ====.
The user answer provided by the customer starts with ==== ANSWER ==== and ends with ==== ANSWER END ====.
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTION ====
{question}
==== QUESTION END ====
==== ANSWER ====
{answer}
==== ANSWER END ====
"""
    [questionnaire.secondary]
    system_message = "You are a Responsible AI expert that can ask questions about Responsible AI to help a customer with concerns related to the responsible usage of AI. You use British English."
    human_message = """Based on the best practices and knowledge base and answers to multiple questions answered by a customer, \
please generate {questions_per_batch} questions that are helpful to this customer to address Responsible AI related concerns. 
Make sure that you ask the user about his or her painpoints and concerns or questions which help to understand the user's problems better and to gather more information - and not how to solve his own problems.
Your purpose is to gather information to help a customer solve Responsible AI related problems. Responsible AI related problems are for example:

- Algorithmic Fairness
- AI governance
- Bias Mitigation
- Public Engagement and AI Strategy
- Transparency and Explainability of AI systems
- Data Privacy and Security
- Human-Centric Approaches
- International Collaboration in the area of AI

Also provide at least 4 possible answers to the questions you generate. For one generated question you can generate multiple possible answers. The generated possible answer should not be more than 2 sentences.
Make sure that the possible answers are explicit and are able to be understood on their own. Please do not use possible answers like 'Both', 'Like the previous possible answer'.

Main questionnaire topic: {questionnaire_topic}
The questions should explore topics related to the main topic "{questionnaire_topic}".

The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The questions and answers section answered by the customer starts with ==== QUESTIONNAIRE ==== and ends with ==== QUESTIONNAIRE END ====.
The user answers are in the section that starts with ==== ANSWERS ==== and ends with ==== ANSWERS END ====.

==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTIONNAIRE ====
{questions_answers}
==== QUESTIONNAIRE END ====
==== ANSWERS ====
{answers}
==== ANSWERS END ====

When generating the questions, please also take the confidence report between ==== CONFIDENCE REPORT ==== and ==== CONFIDENCE REPORT END ==== into account which can improve the overall confidence level:

==== CONFIDENCE REPORT ====
{confidence_report}
==== CONFIDENCE REPORT END ====

"""
    [questionnaire.secondary_regenerate]
    human_message = """Please note: previously a question has been generated, but the end user decided to generate another one.
This was the previous question which the user did not like: '{previous_question}'.
Make sure you generate a different question.
"""
    [questionnaire.clarification]
    system_message = "You are a helpful assistant focused on topics related to Responsible AI. You explain the meaning of questions step by step. You highlight the main topics in bold markdown. I use British English."
    human_message = """Please explain the following question in a way that a layman can understand it:

{question}
"""
    [questionnaire.add_more_suggestions]
    system_message = "You are a Responsible AI expert that is great at finding potential answers for Responsible AI related questions. You use British English."
    human_message = """Given a knowledge base (found between ==== KNOWLEDGE BASE START ==== and ==== KNOWLEDGE BASE END ====) and a set of questions and answers (found between ==== QUESTIONNAIRE START ==== and ==== QUESTIONNAIRE END ====), please generate at most 4 more potential answers to the question below which you can find between ==== QUESTION ==== and ==== QUESTION END ====.
    Please note that some potential answers have previously been generated and you should not repeat them. The previously generated potential answers are found between ==== EXISTING POTENTIAL ANSWERS START ==== and ==== EXISTING POTENTIAL ANSWERS END ====.
    
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTIONNAIRE ====
{questions_answers}
==== QUESTIONNAIRE END ====
==== QUESTION ====
{question}
==== QUESTION END ====
==== EXISTING POTENTIAL ANSWERS START ====
{suggestions}
==== EXISTING POTENTIAL ANSWERS END ====

When generating the potential answers, please also take the confidence report between ==== CONFIDENCE REPORT ==== and ==== CONFIDENCE REPORT END ==== into account so that they can improve the overall confidence level:

==== CONFIDENCE REPORT ====
{confidence_report}
==== CONFIDENCE REPORT END ====

"""

[tagging]
system_message = "You are an expert in terms of getting different types of sentiments from sentences."
human_message = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{answer}
=== INPUT END ===
can you tell me whether there is a question related to data analytics, data governance and strategies in it or not and whether the overall sentiment of the text indicates some sort of confusion?"""
human_message_extraction = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{answer}
=== INPUT END ===
can you extract question related to data analytics, data governance and strategies, if there is one?"""

[clarifications]
system_message = "You are an expert in terms of answering user questions like a professional Responsible AI expert. You use British English."
human_message = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{questions}
=== INPUT END ===
can you please answer all questions related to Responsible AI you see in it? 

Responsible AI related problems are for example:

- Algorithmic Fairness
- AI governance
- Bias Mitigation
- Public Engagement and AI Strategy
- Transparency and Explainability of AI systems
- Data Privacy and Security
- Human-Centric Approaches
- International Collaboration in the area of AI

If you see questions related to topics that are totally unrelated to Responsible AI, please tell the user that you only answer questions about these topics.
Please be concise and limit your replies to around 30 words if possible. 
Do not reply with follow up questions like 'Would you like more information?'."""

[advice]
system_message = """You are a Responsible AI expert that gives advice about Responsible AI to help a customer with concerns related to the responsible usage or creation of strategies around the usaage of AI.
You spend alwayas a few sentences explaining the assumptions and reasoning behind the advice you then present. You use British English."""
human_message = """Based on the best practices and knowledge base and answers to multiple questions answered by a customer, \
please generate a series of at most 5 advices that are helpful to this customer to solve Responsible AI related problems.

Responsible AI related problems are for example:

- Algorithmic Fairness
- AI governance
- Bias Mitigation
- Public Engagement and AI Strategy
- Transparency and Explainability of AI systems
- Data Privacy and Security
- Human-Centric Approaches
- International Collaboration in the area of AI

Also include 4 pieces of advice about what the customer should avoid. In total you should give 5 pieces of advice regarding what should be done and 4 pieces of advice about what should be avoided.
Please also describe 4 potential positive outcomes in case the customer follows the suggested advices.
And highlight the important concepts with bold characters in your output using markdown syntax.

Make sure not to enumerate the advices you give.
The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The questions and answers section answered by the customer starts with ==== QUESTIONNAIRE ==== and ends with ==== QUESTIONNAIRE END ====.
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTIONNAIRE ====
{questions_answers}
==== QUESTIONNAIRE END ====
"""

[extract_ontology]
    system_message = """You are an expert at creating ontologies related to Responsible AI"""
    human_message = """# Ontology from text:

Extract an ontology. Do not draw it, but create a markdown table of relations with 3 columns in this order: source, target, relation name. And also create a list with 2 columns: the first contains the term name and the second column contains the term definition.
the relations should only be mapped to source, target, relations
Use this text as a basis:

```
{questions_answers}

{conditional_advice}

```
"""

[confidence_prompt]
    system_message = "You are an expert at giving Responsible AI related advice based on a question answer dialogue with a customer. You use British English"
    human_message = """Determine how confident you are in terms giving advice to a customer based on a sequence of questions and answers that you can find here:

```
{questions_answers}
```

In order to be confident you should know about the difficulties of the customer. You should know about the following:
* the customer's main problem
* have some detailed information about his problem. Just having a high-level sentence on the problem of the customer like e.g: "AI Ethics" is not enough to be confident.
* you should have also knowledge about what is causing the problem.
* ideally you know more than one cause behind the main problem of the customer. 
* you also need some more background information about the technologies used by the customer to be confident.
* you should also know about the Responsible AI strategies or methodologies applied by the customer to be able to have a high degree of confidence.

Please use the following classifications to this question about the degree of confidence with which you can give advice:

- "outstanding"
- "high"
- "medium"
- "mediocre"
- "low"

For example, you should report an "outstanding" confidence degree when:
You know the main problem of the customer and the causes well. You also know about multiple aspects of Responsible AI like two of:
- Responsible AI ethical standards
- Responsible AI ethical culture
- Responsible AI gouvernance
- Responsible AI strategies
- Responsible AI policies
- AI DevOps
- Stakeholder engagement in model development
related to the customer's organisation which the customer has adopted or plans to adopt.
And you also know the AI landscape of the customer very well.

For example, you should report a "high" confidence degree when:
You know the main problem of the customer and the causes well. You also know about other aspects of Responsible AI like one of:
- Responsible AI ethical standards
- Responsible AI gouvernance
related to the customer's organisation which the customer has adopted or plans to adopt.
The only things missing are information about Responsible AI strategies and policies.

For example, you should report a "medium" confidence degree when:
You know the main problem of the customer and the causes well.
You miss information about Responsible AI on ethical standards, strategies and policies, even though you might have some hints about these.

For example, you should report a "mediocre" confidence degree when:
You know the main problem of the customer and the cause not well. The information about the causes is very limited
You miss information about Responsible AI on ethical standards, strategies and policies and there are almost no hints about these.

For example, you should report a "low" confidence degree when:
You know the main problem of the customer and nothing else. Or you do not even know about the main problem of the user.
No clue on Responsible AI ethical standards, strategies or policies
"""

[reporting]
    [reporting.summarization_prompt]
        system_message = "You are an expert at keyword extraction in long reports. You excel at extracting keywords with concepts from large amounts of text."
        human_message = """
Based on the text below starting from === Questionnaire === and ending at === Questionnaire End === can you please summarize the content of the questionnaire and provided advices?

Please summarize and keep the original sections. So, please keep the following sections and then summarize each, like so:

# Questionnaire
<summary>
# Recommendations
<summary>
# What to avoid
<summary>
# Positive outcomes
<summary>

<summary> is just a placeholder for you summary.

=== Questionnaire ===
{full_questionnaire}
=== Questionnaire End ===
"""
    [reporting.keyword_extraction_prompt]
        system_message = "You are an expert at keyword extraction in long reports in the area of responsible AI. You excel at extracting keywords with concepts from large amounts of text."
        human_message = """
Based on the text below starting from === Questionnaire === and ending at === Questionnaire End === can you please extract the following items from the questionnaire section which always starts with "# Questionnaire":
- stated problems as keywords with problem area as keywords and degree as keywords
- concepts as keywords with corresponding area as keywords

From the recommendations (starting with "# Recommendations") sections can you please extract the following:
- recommendations as keywords
- strategies as keywords

From the "# What to avoid" section can you please extract extract the negative recommendations as keywords.

From the "# Positive outcomes" section can you please extract extract the positive outcomes as keywords.

Regarding the problems and areas, here are some examples of problems:

name: unfair and biased AI models, area: model bias, degree: negative
name: obscure AI model results, area: transparency, degree: moderate
name: irresponsible usage of models, area: accountability, degree: very negative
name: AI models without legal guardrails, area: safety, degree: very negative

Regarding the concepts, here are some examples:

name: ethical AI culture, area: ethics
name: AI adversarial attacks, area: model safety

Regarding the recommendations, here are some examples:

name: invest in Bias Monitoring, area: bias
name: invest in AI DevOps, area: continous improvement
name: implement obfuscation techniques and guardrails, area: privacy

Regarding negative recommendations (about what you should avoid), here are some examples:

- Avoid neglecting bias monitoring
- Avoid ignoring the importance of AI DevOps

Regarding positive outcomes, here are some examples:

- Achieving compliance with data privacy regulations
- Achieving fair and unbiased AI models
- Achieving transparency and explainability of AI models

=== Questionnaire ===
{full_questionnaires}
=== Questionnaire End ===
"""
    [reporting.keyword_document_classifier]
        system_message = "You are an expert at document classification in the area of Responsible AI. You can detect whether some keywords are relevant to a document or not."
        human_message = """
Based on the text below starting from === Questionnaire === and ending at === Questionnaire End === can you please identify whether the following keywords in different categories are relevant to the questionnaire or not.

Category: Problems
{problems}

Category: Problem Areas
{problem_areas}

Category: Concepts 
{concepts}

Category: Recommendations
{recommendations}

Category: Negative recommendations
{negative_recommendations}

Category: Positive outcomes
{positive_outcomes}

=== Questionnaire ===
{full_questionnaire}
=== Questionnaire End ===

"""

[consultants]
    [consultants.evaluation]
        system_message = "You are an analyst that is specialized in rating consultants based on a questionnaire with a customer and a set of analyst CVs."
        human_message = """
Based on the content of a customer questionnaire below starting from === Questionnaire === and ending at === Questionnaire End === , initial advice given to a customer that starts from === Advice Section Start === and ends with === Advice Section End === and a list of CVs starting from === CVs Start === and ending with === CVs End ===, please rate each analyst in terms of their consulting capabilities to help the customer.

There are 5 categories to rate each analyst that reflect the capability of the analyst to help the interviewed customer:

- very suitable
- suitable
- moderately suitable
- hardly suitable
- unsuitable

The questionnaire's questions were answered by the customer and asked by a large language model. The customer should be evaluated based on the answers rather than on the questions.

=== Questionnaire ===
{questions_answers}
=== Questionnaire End ===

=== Advice Section Start ===
{conditional_advice}
=== Advice Section End ===

=== CVs Start ===
{cvs}
=== CVs End ===

At the end of this activity, you should have rated the anaylists with one of the five categories, reflecting the degree to which they can help the interviewed customer based on their CV, professional experience and also skills.
You can also express your degree of confidence in your verdict and also your reasoning that led you to assign a category to a consultant.
"""